{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from magellanhdf import MagellanHDFContainer\n",
    "from afutil import get_patch_metadata, read_or_calc_focal_planes, compile_deterministic_data,\\\n",
    "    feature_vector_generator_fn, plot_results\n",
    "from defocusnetwork import DefocusNetwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of whats happening here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWrapper:\n",
    "    \"\"\"\n",
    "    This class wraps all the essential functionality needed for training single shot autofocus. By default, it reads\n",
    "    Micro-Magellan datasets, but this could be replaced with any data source so long as it provides the following\n",
    "    methods and fields\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: change to code that directly reads magellan once available\n",
    "    def __init__(self, hdf):\n",
    "        self.hdf = hdf\n",
    "\n",
    "\n",
    "    def read_ground_truth_image(self, position_index, z_index):\n",
    "        \"\"\"\n",
    "        Read image in which focus quality can be measured form quality of image\n",
    "        :param pos_index: index of xy position\n",
    "        :param z_index: index of z slice (starting at 0)\n",
    "        :param xy_slice: (cropped region of image)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.hdf.read_image(channel_name='DPC_Bottom', position_index=position_index, \n",
    "                                   relative_z_index=z_index)\n",
    "\n",
    "    def read_prediction_image(self, position_index, z_index, patch_index, split_k):\n",
    "        \"\"\"\n",
    "        Read image used for single shot prediction (i.e. single LED image)\n",
    "        :param pos_index: index of xy position\n",
    "        :param z_index: index of z slice (starting at 0)\n",
    "        :param split_k: number of crops along each dimension\n",
    "        :param patch_index: index of the crop\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        patch_size, patches_per_image = get_patch_metadata((self.get_image_width(),\n",
    "                                                            self.get_image_height()), split_k)\n",
    "        y_tile_index = patch_index // split_k\n",
    "        x_tile_index = patch_index % split_k\n",
    "        xy_slice = [[y_tile_index * patch_size, (y_tile_index + 1) * patch_size],\n",
    "                    [x_tile_index * patch_size, (x_tile_index + 1) * patch_size]]\n",
    "        return self.hdf.read_image(channel_name='autofocus', position_index=position_index,\n",
    "                                   relative_z_index=z_index, xy_slice=xy_slice)\n",
    "\n",
    "    def get_image_width(self):\n",
    "        \"\"\"\n",
    "        :return: image width in pixels\n",
    "        \"\"\"\n",
    "        return self.hdf.tilewidth\n",
    "\n",
    "    def get_image_height(self):\n",
    "        \"\"\"\n",
    "        :return: image height in pixels\n",
    "        \"\"\"\n",
    "        return self.hdf.tileheight\n",
    "\n",
    "    def get_num_z_slices_at(self, position_index):\n",
    "        \"\"\"\n",
    "        return number of z slices (i.e. focal planes) at the given XY position\n",
    "        :param position_index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.hdf.get_num_slices_at(position_index)\n",
    "\n",
    "    def get_pixel_size_z_um(self):\n",
    "        \"\"\"\n",
    "        :return: distance in um between consecutive z slices\n",
    "        \"\"\"\n",
    "        return self.hdf.pixelsizeZ_um\n",
    "\n",
    "    def get_num_xy_positions(self):\n",
    "        \"\"\"\n",
    "        :return: total number of xy positons in data set\n",
    "        \"\"\"\n",
    "        return self.hdf.num_positions\n",
    "\n",
    "    def store_focal_plane(self, name, focal_position):\n",
    "        \"\"\"\n",
    "        Store the computed focal plane as a string, float pair\n",
    "        \"\"\"\n",
    "        self.hdf.write_annotation(name, focal_position)\n",
    "\n",
    "    def read_focal_plane(self, name):\n",
    "        \"\"\"\n",
    "        read a previously computed focal plane\n",
    "        :param name: key corresponding to an xy position for whch focal plane has already been computed\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.hdf.read_annotation(name)\n",
    "\n",
    "    def store_array(self, name, array):\n",
    "        \"\"\"\n",
    "        Store a numpy array containing the design matrix for training the non-deterministic part of the network (i.e.\n",
    "        after the Fourier transform) so that it can be retrained quickly without having to recompute\n",
    "        :param name:\n",
    "        :param array: (n examples) x (d feature length) numpy array\n",
    "        \"\"\"\n",
    "        self.hdf.store_array(name, array)\n",
    "\n",
    "    def read_array(self, name):\n",
    "        \"\"\"\n",
    "        Read and return a previously computed array\n",
    "        :param name:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.hdf.read_array(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load data and compute the ground truth focal planes as targets for training. The show_output flag will create a plot of the averaged high frequency content of the log power spectrum. The maximum of the this plot should correspond to the correct focal plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\nReading precomputed focal plane\n"
     ]
    }
   ],
   "source": [
    "#parameters for the deterministic part of the network\n",
    "#TODO: better explain what these mean\n",
    "deterministic_params = {'non_led_width': 0.1, 'led_width': 0.6, 'tile_split_k': 2}\n",
    "\n",
    "#load data\n",
    "data = [DataWrapper(MagellanHDFContainer(\n",
    "    '/Users/henrypinkard/Desktop/Leukosight data/2018-8-1 A bit more pre collection af/300k 7x7 30um range 50ms_1.hdf'))]\n",
    "\n",
    "#load or compute target focal planes using 22 CPU cores to speed computation\n",
    "train_focal_planes = {dataset: read_or_calc_focal_planes(dataset, split_k=deterministic_params['tile_split_k'],\n",
    "                                                         n_cores=6, show_output=True) for dataset in data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEDs in vertical axis of array:\n",
    "4 12 28 48 83 119 187\n",
    "3 11 27 47 84 120 188\n",
    "3 has defect in it, 4 doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961 sliceposition tuples\n"
     ]
    }
   ],
   "source": [
    "#compute or load already computed design matrices\n",
    "features, targets = compile_deterministic_data(data, train_focal_planes, deterministic_params=deterministic_params)\n",
    "\n",
    "#make genenrator function for providing training examples and seperate validation generator for assessing its progress\n",
    "train_generator = feature_vector_generator_fn(features, targets, mode='training', \n",
    "                                        split_k=deterministic_params['tile_split_k'], training_fraction=0.8)\n",
    "val_generator = feature_vector_generator_fn(features, targets, mode='validation', \n",
    "                                        split_k=deterministic_params['tile_split_k'], training_fraction=0.8)\n",
    "\n",
    "#feed in the dimensions of the cropped input so the inference network knows what to expect\n",
    "patch_size, patches_per_image = get_patch_metadata((data[0].get_image_width(),\n",
    "                                        data[0].get_image_height()), deterministic_params['tile_split_k'])\n",
    "\n",
    "#this call creates network and trains it\n",
    "defocus_prediction_network = DefocusNetwork(input_shape=features.shape[1], train_generator=train_generator,\n",
    "                             val_generator=val_generator, predict_input_shape=[patch_size, patch_size],\n",
    "                             deterministic_params=deterministic_params, regressor_only=True, train_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze performance and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defocus_prediction_network' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f414724013c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#visualize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#validation data drawn from same set used in training, test data is a seperate file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_prediction_defocus, train_target_defocus = defocus_prediction_network.analyze_performance(\n\u001b[0m\u001b[1;32m      4\u001b[0m     feature_vector_generator_fn(train_features, train_targets, mode='all', split_k=deterministic_params['tile_split_k']))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defocus_prediction_network' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#visualize results\n",
    "#validation data drawn from same set used in training, test data is a seperate file\n",
    "train_prediction_defocus, train_target_defocus = defocus_prediction_network.analyze_performance(\n",
    "    feature_vector_generator_fn(train_features, train_targets, mode='all', split_k=deterministic_params['tile_split_k']))\n",
    "\n",
    "test_prediction_defocus, test_target_defocus = defocus_prediction_network.analyze_performance(\n",
    "        feature_vector_generator_fn(test_features, test_targets, mode='all', split_k=deterministic_params['tile_split_k']))\n",
    "\n",
    "#average predictions\n",
    "train_pred_avg, train_target_avg = average_predictions(train_prediction_defocus, train_target_defocus, deterministic_params['tile_split_k'] ** 2)\n",
    "test_pred_avg, test_target_avg = average_predictions(test_prediction_defocus, test_target_defocus, deterministic_params['tile_split_k']**2)\n",
    "\n",
    "plt.figure(1)\n",
    "plot_results(train_prediction_defocus, train_target_defocus, 'Training')\n",
    "plot_results(test_prediction_defocus, test_target_defocus, 'Test', draw_rect=True)\n",
    "plt.legend(['Training data average', 'Test data averaged', 'Ground truth', 'Objective depth of focus'])\n",
    "\n",
    "#show data before tile averaging\n",
    "plt.figure(2)\n",
    "plot_results(train_pred_avg, train_target_avg, 'Training')\n",
    "plot_results(test_pred_avg, test_target_avg, 'Test', draw_rect=True)\n",
    "plt.legend(['Training data average', 'Test data averaged', 'Ground truth', 'Objective depth of focus'])\n",
    "\n",
    "plt.show(block=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
